package scout

import (
	"fmt"
	"reflect"
	"time"

	"github.com/go-rod/rod"
)

// PaginateOption configures pagination behavior.
type PaginateOption func(*paginateOptions)

type paginateOptions struct {
	maxPages    int
	delay       time.Duration
	dedupField  string
	stopOnEmpty bool
}

func paginateDefaults() *paginateOptions {
	return &paginateOptions{
		maxPages:    10,
		delay:       500 * time.Millisecond,
		stopOnEmpty: true,
	}
}

// WithPaginateMaxPages sets the maximum number of pages to scrape. Default: 10.
func WithPaginateMaxPages(n int) PaginateOption {
	return func(o *paginateOptions) { o.maxPages = n }
}

// WithPaginateDelay sets the delay between page loads. Default: 500ms.
func WithPaginateDelay(d time.Duration) PaginateOption {
	return func(o *paginateOptions) { o.delay = d }
}

// WithPaginateDedup sets a struct field name to use for deduplication.
func WithPaginateDedup(fieldName string) PaginateOption {
	return func(o *paginateOptions) { o.dedupField = fieldName }
}

// WithPaginateStopOnEmpty enables stopping when a page yields no new items. Default: true.
func WithPaginateStopOnEmpty() PaginateOption {
	return func(o *paginateOptions) { o.stopOnEmpty = true }
}

// PaginateByClick scrapes items from the current page, clicks the "next" button,
// and repeats until maxPages or no next button is found.
// T must be a struct with `scout:` tags.
func PaginateByClick[T any](p *Page, nextSelector string, opts ...PaginateOption) ([]T, error) {
	o := paginateDefaults()
	for _, fn := range opts {
		fn(o)
	}

	var all []T
	seen := make(map[string]bool)

	for pageNum := 0; pageNum < o.maxPages; pageNum++ {
		items, err := extractAll[T](p)
		if err != nil {
			return all, fmt.Errorf("scout: paginate by click page %d: %w", pageNum+1, err)
		}

		newItems := dedup(items, seen, o.dedupField)
		if o.stopOnEmpty && len(newItems) == 0 && pageNum > 0 {
			break
		}
		all = append(all, newItems...)

		// Try to click next
		has, err := p.Has(nextSelector)
		if err != nil || !has {
			break
		}

		nextEl, err := p.Element(nextSelector)
		if err != nil {
			break
		}

		// Check if the button is visible/interactable
		visible, err := nextEl.Visible()
		if err != nil || !visible {
			break
		}

		if err := nextEl.Click(); err != nil {
			break
		}

		time.Sleep(o.delay)
	}

	return all, nil
}

// PaginateByURL scrapes items by navigating to URLs generated by urlFunc.
// urlFunc receives a 1-based page number and returns the URL to navigate to.
// T must be a struct with `scout:` tags.
func PaginateByURL[T any](b *Browser, urlFunc func(page int) string, opts ...PaginateOption) ([]T, error) {
	o := paginateDefaults()
	for _, fn := range opts {
		fn(o)
	}

	var all []T
	seen := make(map[string]bool)

	for pageNum := 1; pageNum <= o.maxPages; pageNum++ {
		url := urlFunc(pageNum)
		page, err := b.NewPage(url)
		if err != nil {
			return all, fmt.Errorf("scout: paginate by url page %d: %w", pageNum, err)
		}

		if err := page.WaitLoad(); err != nil {
			_ = page.Close()
			return all, fmt.Errorf("scout: paginate by url page %d wait: %w", pageNum, err)
		}

		items, err := extractAll[T](page)
		_ = page.Close()
		if err != nil {
			return all, fmt.Errorf("scout: paginate by url page %d extract: %w", pageNum, err)
		}

		newItems := dedup(items, seen, o.dedupField)
		if o.stopOnEmpty && len(newItems) == 0 && pageNum > 1 {
			break
		}
		all = append(all, newItems...)

		if pageNum < o.maxPages {
			time.Sleep(o.delay)
		}
	}

	return all, nil
}

// PaginateByScroll scrapes items by scrolling to the bottom and waiting for new content.
// T must be a struct with `scout:` tags. itemSelector identifies the repeating items.
func PaginateByScroll[T any](p *Page, itemSelector string, opts ...PaginateOption) ([]T, error) {
	o := paginateDefaults()
	for _, fn := range opts {
		fn(o)
	}

	var all []T
	seen := make(map[string]bool)

	for pageNum := 0; pageNum < o.maxPages; pageNum++ {
		items, err := extractAll[T](p)
		if err != nil {
			return all, fmt.Errorf("scout: paginate by scroll: %w", err)
		}

		newItems := dedup(items, seen, o.dedupField)
		if o.stopOnEmpty && len(newItems) == 0 && pageNum > 0 {
			break
		}
		all = append(all, newItems...)

		// Get current count of items
		countBefore, _ := countElements(p, itemSelector)

		// Scroll to bottom
		_, err = p.Eval(`() => window.scrollTo(0, document.body.scrollHeight)`)
		if err != nil {
			break
		}

		time.Sleep(o.delay)

		// Check if new items appeared
		countAfter, _ := countElements(p, itemSelector)
		if countAfter <= countBefore {
			break // No new items loaded
		}
	}

	return all, nil
}

// PaginateByLoadMore scrapes items by clicking a "load more" button repeatedly.
// T must be a struct with `scout:` tags.
func PaginateByLoadMore[T any](p *Page, loadMoreSelector string, opts ...PaginateOption) ([]T, error) {
	o := paginateDefaults()
	for _, fn := range opts {
		fn(o)
	}

	var all []T
	seen := make(map[string]bool)

	for pageNum := 0; pageNum < o.maxPages; pageNum++ {
		items, err := extractAll[T](p)
		if err != nil {
			return all, fmt.Errorf("scout: paginate by load more: %w", err)
		}

		newItems := dedup(items, seen, o.dedupField)
		if o.stopOnEmpty && len(newItems) == 0 && pageNum > 0 {
			break
		}
		all = append(all, newItems...)

		// Try clicking load more
		has, err := p.Has(loadMoreSelector)
		if err != nil || !has {
			break
		}

		loadMoreEl, err := p.Element(loadMoreSelector)
		if err != nil {
			break
		}

		visible, err := loadMoreEl.Visible()
		if err != nil || !visible {
			break
		}

		if err := loadMoreEl.Click(); err != nil {
			break
		}

		time.Sleep(o.delay)
	}

	return all, nil
}

// --- internal helpers ---

// extractAll extracts all items of type T from the page.
// It finds repeating container elements by looking at the first scout-tagged field,
// then walks up to each field's parent to use as scope for extracting the full struct.
func extractAll[T any](p *Page) ([]T, error) {
	var zero T
	rt := reflect.TypeOf(zero)
	if rt.Kind() == reflect.Ptr {
		rt = rt.Elem()
	}
	if rt.Kind() != reflect.Struct {
		return nil, fmt.Errorf("scout: paginate: T must be a struct type")
	}

	// Find the first scout-tagged field to locate items
	var firstSelector string
	for i := 0; i < rt.NumField(); i++ {
		tag := rt.Field(i).Tag.Get("scout")
		if tag == "" || tag == "-" {
			continue
		}
		firstSelector, _ = parseTag(tag)
		break
	}
	if firstSelector == "" {
		return nil, fmt.Errorf("scout: paginate: T has no scout-tagged fields")
	}

	// Find all elements matching the first field's selector
	fieldEls, err := p.page.Elements(firstSelector)
	if err != nil || len(fieldEls) == 0 {
		return nil, nil
	}

	// Walk up each match to its parent container using ElementByJS
	var items []T
	for _, el := range fieldEls {
		parent, err := p.page.ElementByJS(rod.Eval(`() => this.parentElement`).This(el.Object))
		if err != nil {
			continue
		}

		item := reflect.New(rt).Elem()
		if err := extractStruct(p.page, parent, item); err != nil {
			continue
		}
		items = append(items, item.Interface().(T))
	}

	return items, nil
}

func countElements(p *Page, selector string) (int, error) {
	els, err := p.Elements(selector)
	if err != nil {
		return 0, err
	}
	return len(els), nil
}

func dedup[T any](items []T, seen map[string]bool, dedupField string) []T {
	if dedupField == "" {
		return items
	}

	var result []T
	for _, item := range items {
		rv := reflect.ValueOf(item)
		if rv.Kind() == reflect.Ptr {
			rv = rv.Elem()
		}
		fv := rv.FieldByName(dedupField)
		if !fv.IsValid() {
			result = append(result, item)
			continue
		}
		key := fmt.Sprintf("%v", fv.Interface())
		if !seen[key] {
			seen[key] = true
			result = append(result, item)
		}
	}
	return result
}
